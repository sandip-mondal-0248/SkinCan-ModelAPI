{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-22T09:12:43.582046Z",
     "iopub.status.busy": "2025-01-22T09:12:43.581766Z",
     "iopub.status.idle": "2025-01-22T09:12:45.046226Z",
     "shell.execute_reply": "2025-01-22T09:12:45.045208Z",
     "shell.execute_reply.started": "2025-01-22T09:12:43.582022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# TensorFlow / Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import (\n",
    "    DenseNet169, InceptionV3, Xception, MobileNetV2, ResNet152, EfficientNetB4\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, Dense, Dropout, Conv2D,\n",
    "    GlobalAveragePooling2D, GlobalMaxPooling2D,\n",
    "    Multiply, Add, Reshape, Activation\n",
    ")\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/input/skin-cancer-malignant-vs-benign/train' # Path to training data\n",
    "validation_dir = '/kaggle/input/skin-cancer-malignant-vs-benign/test' # Path to validation data\n",
    "\n",
    "classes = os.listdir(train_dir)\n",
    "image_paths = [] \n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(train_dir, cls)\n",
    "    images = os.listdir(class_dir)\n",
    "    for img in images:\n",
    "        image_paths.append((os.path.join(class_dir, img), cls))\n",
    "\n",
    "# Randomly select 16 images from the dataset and display them\n",
    "random_images = random.sample(image_paths, 16)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path, class_name = random_images[i]\n",
    "    img = mpimg.imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off') \n",
    "    ax.set_title(class_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:12:52.025068Z",
     "iopub.status.busy": "2025-01-22T09:12:52.024773Z",
     "iopub.status.idle": "2025-01-22T09:12:52.205358Z",
     "shell.execute_reply": "2025-01-22T09:12:52.204598Z",
     "shell.execute_reply.started": "2025-01-22T09:12:52.025045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Display the number of images per class in the training data\n",
    "classes = [cls.name for cls in train_dir.iterdir() if cls.is_dir()]\n",
    "image_count = {cls: len(list((train_dir / cls).iterdir())) for cls in classes}\n",
    "image_count = dict(sorted(image_count.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(image_count.keys(), image_count.values(), color='skyblue')\n",
    "\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.5,\n",
    "             f'{int(bar.get_height())}', ha='center', va='bottom', color='black')\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per Class in the Training Data')\n",
    "plt.xticks(rotation=90, ha='right')  \n",
    "plt.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T09:12:57.399119Z",
     "iopub.status.busy": "2025-01-22T09:12:57.398839Z",
     "iopub.status.idle": "2025-01-22T09:12:57.606098Z",
     "shell.execute_reply": "2025-01-22T09:12:57.605441Z",
     "shell.execute_reply.started": "2025-01-22T09:12:57.399098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Display the number of images per class in the test data\n",
    "classes = [cls.name for cls in validation_dir.iterdir() if cls.is_dir()]\n",
    "image_count = {cls: len(list((validation_dir / cls).iterdir())) for cls in classes}\n",
    "image_count = dict(sorted(image_count.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(image_count.keys(), image_count.values(), color='orange')\n",
    "\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.5,  \n",
    "             f'{int(bar.get_height())}', ha='center', va='bottom', color='black')\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images per Class in the Test Data')\n",
    "plt.xticks(rotation=90, ha='right') \n",
    "plt.tight_layout()  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T16:09:54.739740Z",
     "iopub.status.busy": "2025-01-22T16:09:54.739470Z",
     "iopub.status.idle": "2025-01-22T16:48:45.152438Z",
     "shell.execute_reply": "2025-01-22T16:48:45.151686Z",
     "shell.execute_reply.started": "2025-01-22T16:09:54.739720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CBAM Attention Block\n",
    "def cbam_block(input_tensor, reduction_ratio=16):\n",
    "    # Channel Attention\n",
    "    channel = GlobalAveragePooling2D()(input_tensor)\n",
    "    channel = Dense(input_tensor.shape[-1] // reduction_ratio, activation='relu')(channel)\n",
    "    channel = Dense(input_tensor.shape[-1], activation='sigmoid')(channel)\n",
    "    channel = Reshape((1, 1, input_tensor.shape[-1]))(channel)\n",
    "    channel_attention = Multiply()([input_tensor, channel])\n",
    "    \n",
    "    # Spatial Attention\n",
    "    spatial = Conv2D(1, kernel_size=(7, 7), padding='same', activation='sigmoid')(channel_attention)\n",
    "    spatial_attention = Multiply()([channel_attention, spatial])\n",
    "    \n",
    "    return spatial_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set image size and batch size\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "test_labels = validation_generator.classes\n",
    "target_names = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models with different architectures\n",
    "def create_model(base_model_class, input_shape=(224, 224, 3)):\n",
    "    base_model = base_model_class(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    base_model.trainable = False \n",
    "    \n",
    "    # Apply CBAM\n",
    "    attention_output = cbam_block(base_model.output)\n",
    "    \n",
    "    x = Flatten()(attention_output)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer=RMSprop(learning_rate=2e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to try\n",
    "models = [\n",
    "    ('DenseNet169', DenseNet169),\n",
    "    ('InceptionV3', InceptionV3),\n",
    "    ('Xception', Xception),\n",
    "    ('MobileNetV2', MobileNetV2),\n",
    "    ('ResNet152', ResNet152),\n",
    "    ('EfficientNetB4', EfficientNetB4)\n",
    "]\n",
    "\n",
    "best_model_name = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model_class in models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    model = create_model(model_class)\n",
    "    \n",
    "    # Define checkpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=f'{model_name}.keras',\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "\n",
    "    # Find the best model based on validation accuracy\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_name = model_name\n",
    "\n",
    "    print(f\"{model_name} validation accuracy: {val_accuracy}\")\n",
    "\n",
    "print(f\"The best performing model is {best_model_name} with a validation accuracy of {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:23:54.240022Z",
     "iopub.status.busy": "2025-01-23T13:23:54.239710Z",
     "iopub.status.idle": "2025-01-23T13:24:06.634410Z",
     "shell.execute_reply": "2025-01-23T13:24:06.633573Z",
     "shell.execute_reply.started": "2025-01-23T13:23:54.239997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Fuzzy Rank-based Ensemble:\n",
    "\n",
    "# Function to get scores from the model\n",
    "def getScore(model,test_imgs):\n",
    "  res = model.predict(test_imgs)\n",
    "  return res \n",
    "\n",
    "# Generate rank based on scores using a exponential function\n",
    "def generateRank1(score,class_no):\n",
    "  rank = np.zeros([class_no,1])\n",
    "  scores = np.zeros([class_no,1])\n",
    "  scores = score\n",
    "  for i in range(class_no):\n",
    "      rank[i] = 1 - np.exp(-((scores[i]-1)**2)/2.0)\n",
    "  return rank\n",
    "\n",
    "# Generate rank based on scores using a tanh function\n",
    "def generateRank2(score,class_no):\n",
    "  rank = np.zeros([class_no,1])\n",
    "  scores = np.zeros([class_no,1])\n",
    "  scores = score\n",
    "  for i in range(class_no):\n",
    "      rank[i] = 1 - np.tanh(((scores[i]-1)**2)/2)\n",
    "  return rank\n",
    "\n",
    "# Function to perform fusion of the results from three models\n",
    "def doFusion(res1,res2,res3,label,class_no):\n",
    "  cnt = 0\n",
    "  id = []\n",
    "  for i in range(len(res1)):\n",
    "      rank1 = generateRank1(res1[i],class_no)*generateRank2(res1[i],class_no)\n",
    "      rank2 = generateRank1(res2[i],class_no)*generateRank2(res2[i],class_no)\n",
    "      rank3 = generateRank1(res3[i],class_no)*generateRank2(res3[i],class_no)\n",
    "      rankSum = rank1 + rank2 + rank3\n",
    "      rankSum = np.array(rankSum)\n",
    "      scoreSum = 1 - (res1[i] + res2[i] + res3[i])/3\n",
    "      scoreSum = np.array(scoreSum)\n",
    "      \n",
    "      fusedScore = (rankSum.T)*scoreSum\n",
    "      cls = np.argmin(rankSum)\n",
    "      id.append(cls)\n",
    "  return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:24:10.123672Z",
     "iopub.status.busy": "2025-01-23T13:24:10.123048Z",
     "iopub.status.idle": "2025-01-23T13:24:17.010472Z",
     "shell.execute_reply": "2025-01-23T13:24:17.009710Z",
     "shell.execute_reply.started": "2025-01-23T13:24:10.123639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function that trains and saves the model\n",
    "def train_and_save_model(model_name, base_model_class, checkpoint_path):\n",
    "    print(f\"\\nTraining {model_name}...\\n\")\n",
    "    model = create_model(base_model_class)\n",
    "    \n",
    "    # Define checkpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train and validate the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=25,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T13:24:32.086396Z",
     "iopub.status.busy": "2025-01-23T13:24:32.086090Z",
     "iopub.status.idle": "2025-01-23T14:08:31.758687Z",
     "shell.execute_reply": "2025-01-23T14:08:31.757767Z",
     "shell.execute_reply.started": "2025-01-23T13:24:32.086373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DenseNet169_history = train_and_save_model(\"DenseNet169\", DenseNet169, \"DenseNet169_best.keras\")\n",
    "InceptionV3_history = train_and_save_model(\"InceptionV3\", InceptionV3, \"InceptionV3_best.keras\")\n",
    "MobileNetV2_history = train_and_save_model(\"MobileNetV2\", MobileNetV2, \"MobileNetV2_best.keras\")\n",
    "\n",
    "DenseNet169_path = '/kaggle/working/DenseNet169_best.keras'\n",
    "InceptionV3_path = '/kaggle/working/InceptionV3_best.keras'\n",
    "MobileNetV2_path = '/kaggle/working/MobileNetV2_best.keras'\n",
    "\n",
    "# Load the saved models\n",
    "model0 = load_model(DenseNet169_path)\n",
    "model1 = load_model(InceptionV3_path)\n",
    "model2 = load_model(MobileNetV2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T14:11:51.980934Z",
     "iopub.status.busy": "2025-01-23T14:11:51.980613Z",
     "iopub.status.idle": "2025-01-23T14:11:53.173133Z",
     "shell.execute_reply": "2025-01-23T14:11:53.172116Z",
     "shell.execute_reply.started": "2025-01-23T14:11:51.980911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training history for each model\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"DenseNet169 Training History: \")\n",
    "plot_training_history(DenseNet169_history)\n",
    "\n",
    "print(\"InceptionV3 Training History: \")\n",
    "plot_training_history(InceptionV3_history)\n",
    "\n",
    "print(\"MobileNetV2 Training History: \")\n",
    "plot_training_history(MobileNetV2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T14:12:00.615333Z",
     "iopub.status.busy": "2025-01-23T14:12:00.615045Z",
     "iopub.status.idle": "2025-01-23T14:13:18.174373Z",
     "shell.execute_reply": "2025-01-23T14:13:18.173579Z",
     "shell.execute_reply.started": "2025-01-23T14:12:00.615310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"BASE LEARNERS ACCURACY: \")\n",
    "model0.evaluate(validation_generator)\n",
    "model1.evaluate(validation_generator)\n",
    "model2.evaluate(validation_generator)\n",
    "\n",
    "# Predict and evaluate the models\n",
    "res1 = model0.predict(validation_generator)\n",
    "res2 = model1.predict(validation_generator) \n",
    "res3 = model2.predict(validation_generator)\n",
    "\n",
    "# Perform ensemble fusion\n",
    "predictedClass = doFusion(res1,res2,res3,test_labels,class_no=num_classes)\n",
    "\n",
    "leb1 = np.argmax(res1,axis=-1)\n",
    "leb2 = np.argmax(res2,axis=-1)\n",
    "leb3 = np.argmax(res3,axis=-1)\n",
    "\n",
    "print('Densenet-169 base learner:')\n",
    "print(classification_report(test_labels, leb1,target_names = target_names,digits=4))\n",
    "print('Inception base learner:')\n",
    "print(classification_report(test_labels, leb2,target_names = target_names,digits=4))\n",
    "print('MobileNetV2 base learner:')\n",
    "print(classification_report(test_labels, leb3,target_names = target_names,digits=4))\n",
    "\n",
    "print('Ensembled:')\n",
    "print(classification_report(test_labels, predictedClass,target_names = target_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T14:14:33.555565Z",
     "iopub.status.busy": "2025-01-23T14:14:33.555216Z",
     "iopub.status.idle": "2025-01-23T14:14:34.216613Z",
     "shell.execute_reply": "2025-01-23T14:14:34.215751Z",
     "shell.execute_reply.started": "2025-01-23T14:14:33.555538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Confusion Matrix of DenseNet169: \")\n",
    "cm = confusion_matrix(test_labels, leb1)\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "print(\"Confusion Matrix of InceptionV3: \")\n",
    "cm = confusion_matrix(test_labels, leb2)\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "print(\"Confusion Matrix of MobileNetV2: \")\n",
    "cm = confusion_matrix(test_labels, leb3)\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "print(\"Confusion Matrix of Ensembled: \")\n",
    "cm = confusion_matrix(test_labels, predictedClass)\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "plot_confusion_matrix(cm, class_names)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 174469,
     "sourceId": 505351,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
